\begin{abstract}{扩散模型；神经网络；人工智能；边缘设备；神经网络设计；C语言}  %关键词位置
    \par 最近，AIGC的爆火已经颠覆了诸多领域。其中最核心的便是扩散模型（Diffusion Model）\textsuperscript{\cite{ho_denoising_nodate}}。
    它是一类基于神经网络的生成模型，通过在前向阶段逐步对图像施加噪声，直至图像变成高斯噪声，
    然后在逆向阶段学习从噪声还原为原始图像的过程。

    \par 神经网络的发展可以追溯到20世纪40年代至60年代的控制论时期，经历了80年代至90年代中期的联结主义，直至2006年以来的深度学习时期。
    在这个过程中，出现了多层感知器、反向传播神经网络、卷积神经网络（CNN）以及递归神经网络等多种网络模型\textsuperscript{\cite{macukow_neural_2016}}。

    \par 目前，边缘设备的人工智能模型部署需求逐渐增大。
    为了实现低延迟、高效率与实时处理这几种特性，通常需要对人工智能模型进行优化和压缩，以适应资源受限的边缘设备\textsuperscript{\cite{saha_machine_2022}\cite{sakr_machine_2020}}。
    边缘部署需要允许对人工智能模型进行自定义以及完善的模型自适应，以满足边缘设备、应用或者用户的需求。

    \par 因此，这篇论文介绍了一套全面的基于C语言的神经网络API，旨在建立一套可以使研究人员、开发者和从业者能够有效地构建、训练和部署用于各种应用的神经网络模型。
    所设计的API采用模块化的思路以及可扩展化的架构，提供高性能的计算能力，同时确保跨平台的兼容性。

    \par 同时，针对现有的C语言神经网络库进行了批判性分析，讨论了它们在性能、可扩展性和易用性方面的局限性。
    这一分析从侧面提出了设计本文API的动机：解决这些不足，并为人工智能从业者提供流畅的开发体验。

    \par 本文重点介绍的是如何使用API来构建和训练神经网络。
    全面覆盖了模型定义、添加层（如卷积、池化、全连接）、设置激活函数、设置损失函数、配置优化器以及数据预处理流程。
    这些组件设计为可高度自定义的模式，使神经网络设计者能够构建和调整神经网络架构，以满足其特定的需求。
    
    \par 在整个API的设计过程中，探讨了利用大型语言模型（LLMs）进行代码生成的潜力，重点介绍了Claude 3 Sonnet为何成为为此目的而选择的语言模型。
    本文横向比较了不同大型语言模型构建项目代码的能力。
    
    \par 为了确保API的高效使用、可维护和可扩展，采用比较灵活的设计模式，如面向对象的设计原则和完善的内存管理技术。
    通过与其他类似开源库的对比测试，对比了API在不同硬件平台和工作负载下的计算效率和资源利用情况。
    
    \par 最后，本文概述了未来的API的设计、维护和完善方向，讨论了计划中的功能和改进，以增强API的功能，并应对神经网络领域的新兴趋势。
\end{abstract}


\begin{abstractEng}{Diffusion Model; Neural Network; Artificial Intelligence; Edge Device; Neural Network Design; C}
    \par The Diffusion Model is a type of generative model, 
    different from other generative models such as Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN). 
    It works by gradually applying noise to an image during the forward phase until the image becomes Gaussian noise, 
    and then learning to restore the original image from the noise during the reverse phase. 
    This is also the basic idea behind neural network models, which generate new data by learning the distribution of data.

    \par The development of neural networks can be traced back to the cybernetics period from the 1940s to the 1960s, 
    through the connectionism of the mid-1980s to the mid-1990s, and up to the deep learning era since 2006. 
    During this process, various network models emerged, 
    including multilayer perceptrons, backpropagation neural networks, Convolutional Neural Networks (CNN), and recurrent neural networks.

    \par Currently, there is a growing demand for deploying artificial intelligence models on edge devices. 
    To achieve low latency, high efficiency, and real-time processing, 
    it is often necessary to optimize and compress large AI models to fit the resource constraints of edge devices. 
    Edge deployment requires the ability to customize and adapt AI models to meet the needs of edge devices, applications, or users.

    \par This paper presents a comprehensive set of C-based Neural Network APIs 
    designed to enable researchers, developers, and practitioners to efficiently build, train, 
    and deploy neural networks for various applications. 
    The proposed APIs adopt a modular and extensible architecture, 
    offering high-performance computing capabilities while ensuring cross-platform compatibility.

    \par The current state of existing neural network libraries in C is critically analyzed, 
    highlighting their limitations in terms of performance, scalability, and ease of use. 
    This analysis serves as the motivation for introducing a new, 
    cutting-edge API tailored to address these shortcomings and provide a seamless development experience for neural network practitioners.
    
    \par Building and training neural networks is a central focus, 
    with comprehensive coverage of model definition techniques, various layer types 
    (e.g., convolutional, pooling, fully-connected), activation functions, loss functions, optimizers, and data preprocessing pipelines. 
    These components are designed to be highly configurable, 
    enabling users to construct and fine-tune neural network architectures to meet their specific requirements.

    \par Best practices and design patterns, such as object-oriented design principles and robust memory management techniques, 
    are presented to ensure efficient, maintainable, and scalable code. 
    Performance benchmarking against other popular libraries is conducted to 
    evaluate the API's computational efficiency and resource utilization across various hardware platforms and workloads.

    \par Performance benchmarking against other libraries is conducted to evaluate the API's computational efficiency. 
    Real-world usage examples, such as image classification, are provided to illustrate the practical applications of the proposed APIs.

    \par Finally, the paper outlines a roadmap and future directions, 
    discussing planned features and improvements to enhance the APIs' capabilities and address emerging trends in the field of neural networks.
\end{abstractEng}